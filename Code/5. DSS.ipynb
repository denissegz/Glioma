{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768df2e6-cd3d-418d-81b0-f8cc2f5ea260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sksurv.meta import EnsembleSelection\n",
    "from sksurv.svm import FastSurvivalSVM, FastKernelSurvivalSVM\n",
    "from sksurv.tree import SurvivalTree\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, VarianceThreshold, RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn import set_config\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from functools import cache\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "randomState = 42 # tip of the cap to Douglas Adams\n",
    "set_config(transform_output=\"pandas\")\n",
    "Verbosity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91f1d93-4130-4665-a7bf-bfd083095f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fianl_clean_data = pd.read_pickle('fianl_clean_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf1bd61-6e3a-4224-879a-dea747b5ae58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         cg13869341  cg24669183  cg15560884  cg01014490  cg17505339  \\\n",
       "369.0     0.839668    0.622626    0.724557    0.013253    0.954777   \n",
       "96.0      0.887214    0.557666    0.709998    0.016885    0.909813   \n",
       "423.0     0.878038    0.821218    0.665864    0.017920    0.925042   \n",
       "370.0     0.857886    0.765783    0.677472    0.008228    0.952425   \n",
       "459.0     0.851489    0.727787    0.790580    0.011233    0.909230   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "1097.0    0.916326    0.895041    0.689632    0.016836    0.931332   \n",
       "1101.0    0.888906    0.668552    0.649029    0.016283    0.924404   \n",
       "781.0     0.870023    0.920880    0.748541    0.017143    0.889875   \n",
       "782.0     0.842035    0.886402    0.708638    0.019360    0.936385   \n",
       "1089.0    0.837559    0.884514    0.680507    0.022893    0.913718   \n",
       "\n",
       "        cg11954957  cg16736630  cg05898754  cg03128332  cg16619049  ...  \\\n",
       "369.0     0.778680    0.937495    0.574408    0.256935    0.346032  ...   \n",
       "96.0      0.859712    0.885200    0.341588    0.088496    0.115528  ...   \n",
       "423.0     0.815867    0.818661    0.365594    0.115413    0.206443  ...   \n",
       "370.0     0.691414    0.915337    0.337019    0.258516    0.078493  ...   \n",
       "459.0     0.632709    0.839941    0.651802    0.071423    0.607906  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "1097.0    0.839926    0.844833    0.409893    0.394330    0.745188  ...   \n",
       "1101.0    0.800694    0.893177    0.296759    0.086829    0.106427  ...   \n",
       "781.0     0.804467    0.861620    0.293793    0.111087    0.114814  ...   \n",
       "782.0     0.882608    0.903366    0.666527    0.125232    0.721306  ...   \n",
       "1089.0    0.818161    0.898309    0.419754    0.121404    0.850379  ...   \n",
       "\n",
       "        gender  initial_pathologic_dx_year  birth_days_to   OS  OS.time  DSS  \\\n",
       "369.0        1                      2004.0       -22392.0  1.0     24.0  1.0   \n",
       "96.0         0                      2001.0       -23343.0  1.0   1448.0  1.0   \n",
       "423.0        1                      2008.0       -18659.0  1.0    141.0  1.0   \n",
       "370.0        1                      2003.0       -19237.0  1.0     42.0  1.0   \n",
       "459.0        1                      2008.0       -15950.0  0.0    953.0  0.0   \n",
       "...        ...                         ...            ...  ...      ...  ...   \n",
       "1097.0       0                      2013.0        -9005.0  0.0    714.0  0.0   \n",
       "1101.0       1                      2013.0       -24411.0  1.0    245.0  1.0   \n",
       "781.0        1                      2013.0       -12578.0  0.0      7.0  0.0   \n",
       "782.0        1                      2013.0       -16202.0  0.0      6.0  0.0   \n",
       "1089.0       0                      2010.0       -15629.0  1.0    954.0  1.0   \n",
       "\n",
       "        DSS.time  PFI  PFI.time  classification.2021_simplified.labels  \n",
       "369.0       24.0  1.0      24.0                                      1  \n",
       "96.0      1448.0  1.0     797.0                                      1  \n",
       "423.0      141.0  1.0      81.0                                      1  \n",
       "370.0       42.0  1.0      42.0                                      1  \n",
       "459.0      953.0  0.0     953.0                                      0  \n",
       "...          ...  ...       ...                                    ...  \n",
       "1097.0     714.0  0.0     714.0                                      0  \n",
       "1101.0     245.0  1.0     245.0                                      1  \n",
       "781.0        7.0  0.0       7.0                                      2  \n",
       "782.0        6.0  0.0       6.0                                      0  \n",
       "1089.0     954.0  1.0     455.0                                      0  \n",
       "\n",
       "[578 rows x 403966 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fianl_clean_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed74ac1-ba6b-4e3f-a1ce-2c6340cb2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break out the target\n",
    "# print(mergeSurvivalClinicalGene.describe())\n",
    "y = fianl_clean_data[['DSS']]\n",
    "# y['DSSBool'] = y.DSS.astype(bool) # this is the format scikit-survival needs\n",
    "fianl_clean_data.drop(columns=['DSS'], inplace=True)\n",
    "# mergeSurvivalClinicalGene.describe()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "597c2050-b650-48eb-8ad0-840135716809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fianl_clean_data, y, test_size=0.2, random_state=randomState, stratify=y)\n",
    "\n",
    "if Verbosity > 0:\n",
    "    print('X_train', X_train.shape), print('y_train', y_train.shape)\n",
    "    # print(np.bincount(y_train))\n",
    "    print('X_test', X_test.shape), print('y_test', y_test.shape)\n",
    "    # print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ae95e0-221f-4176-89b6-20eaa4d03994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've split and stratified, supplement y with other elements of target\n",
    "y['DSS.time'] = fianl_clean_data['DSS.time']\n",
    "y_train['DSS.time'] = X_train['DSS.time']\n",
    "y_test['DSS.time'] = X_test['DSS.time']\n",
    "fianl_clean_data.drop(columns='DSS.time', inplace=True)\n",
    "X_train.drop(columns='DSS.time', inplace=True)\n",
    "X_test.drop(columns='DSS.time', inplace=True)\n",
    "# yDSS_train = [[y_train, X_train['DSS.time']]\n",
    "# yDSS_train = [[y_test, X_test['DSS.time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd82ccb-cfb8-43a2-a91f-a1290ea22236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boolean target that scikit-survival needs\n",
    "y['DSSBool'] = y.DSS.astype(bool)\n",
    "y_train['DSSBool'] = y_train.DSS.astype(bool)\n",
    "y_test['DSSBool'] = y_test.DSS.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c28ab2c-13b9-4b8f-8190-e0c3da0200db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DSS.time from days to months\n",
    "# this makes charts easier to interpret\n",
    "y['DSS.time.months'] = y['DSS.time'] / 30.417\n",
    "\n",
    "if Verbosity > 0:\n",
    "    y['DSS.time.months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0669db-986a-4a1d-bc37-0a5fede1caac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Kaplan-Meier Survival Function for the entire dataset\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "\n",
    "surv_time, survival_prob, conf_int = kaplan_meier_estimator(\n",
    "    y.DSSBool, y['DSS.time.months'], conf_type=\"log-log\"\n",
    "    # data_y[\"Status\"], data_y[\"Survival_in_days\"], conf_type=\"log-log\"\n",
    ")\n",
    "plt.step(surv_time, survival_prob, where=\"post\")\n",
    "plt.fill_between(surv_time, conf_int[0], conf_int[1], alpha=0.25, step=\"post\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Kaplan-Meier Survival Function')\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$ (months)\")\n",
    "plt.savefig(\"Kaplan-Meier Survival Function.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90352e80-3ec6-4ac5-9132-1951d22bf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to format target for Scikit-Survival\n",
    "#\n",
    "def format_target_for_Scikit_Survival(y):\n",
    "    # y: event boolean and event time, eg. y_train[['DSSBool', 'DSS.time']]\n",
    "    # List of tuples\n",
    "    aux = [(e1,e2) for e1,e2 in np.array(y)]\n",
    "    # aux = [(e1,e2) for e1,e2 in np.array(y[['DSSBool', 'DSS.time']])]\n",
    "\n",
    "    #Structured array\n",
    "    yDSS = np.array(aux, dtype=[('Status', '?'), ('Survival_in_months', '<f8')])\n",
    "    # print(yDSS)\n",
    "\n",
    "    return yDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5a687a-a332-4dda-ab96-578daccc1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format target for Scikit-Survival\n",
    "\n",
    "#Structured array\n",
    "yDSS = format_target_for_Scikit_Survival(y[['DSSBool', 'DSS.time']])\n",
    "if Verbosity > 0:\n",
    "    yDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62fe7689-9d04-4820-ac9b-6af6b23f5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format target for Scikit-Survival\n",
    "yDSS_train = format_target_for_Scikit_Survival(y_train[['DSSBool', 'DSS.time']])\n",
    "if Verbosity > 0:\n",
    "    yDSS_train\n",
    "\n",
    "yDSS_test = format_target_for_Scikit_Survival(y_test[['DSSBool', 'DSS.time']])\n",
    "if Verbosity > 0:\n",
    "    yDSS_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6662afe-605c-41e2-ba6f-5ffba794ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create additional target at 'years' years in to the study\n",
    "def create_target_year(X, y, years):\n",
    "    DSSBinary = []\n",
    "    DSSTimeMonths = []\n",
    "\n",
    "    for sample_idx in range(len(y)):\n",
    "        # print(y.iloc[sample_idx])\n",
    "        if y.iloc[sample_idx]['DSS.time.months'] <= (years * 12):\n",
    "            # print('In Cohort, DSS= ', y.iloc[sample_idx].DSS)\n",
    "            DSSBinary.append(y.iloc[sample_idx].DSS)\n",
    "            DSSTimeMonths.append(y.iloc[sample_idx]['DSS.time.months'])\n",
    "        else:\n",
    "            DSSBinary.append(0) # censored\n",
    "            DSSTimeMonths.append(years * 12)\n",
    "\n",
    "    DSSBinary = pd.Series(DSSBinary)\n",
    "    DSSBool = DSSBinary.astype(bool)\n",
    "    DSSTimeMonths = pd.Series(DSSTimeMonths)\n",
    "\n",
    "    # create balanced test and train sets\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, DSSBinary, test_size=0.2, random_state=randomState, stratify=DSSBinary)\n",
    "\n",
    "    if Verbosity > 0:\n",
    "        print('ytrain: ', np.bincount(ytrain))\n",
    "        print('ytrain: ', ytrain)\n",
    "        print('ytest: ', np.bincount(ytest))\n",
    "        print('ytrain: ', ytrain)\n",
    "\n",
    "    return Xtrain, Xtest, ytrain, ytest, DSSBinary, DSSBool, DSSTimeMonths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fa0b00-6274-4877-8059-aaa9d2ad542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSS</th>\n",
       "      <td>578.0</td>\n",
       "      <td>0.316609</td>\n",
       "      <td>0.465556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSS.time</th>\n",
       "      <td>578.0</td>\n",
       "      <td>841.141869</td>\n",
       "      <td>864.070960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>577.500000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>5546.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSS.time.months</th>\n",
       "      <td>578.0</td>\n",
       "      <td>27.653676</td>\n",
       "      <td>28.407501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.994411</td>\n",
       "      <td>18.986093</td>\n",
       "      <td>35.966729</td>\n",
       "      <td>182.332248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count        mean         std  min         25%         50%  \\\n",
       "DSS              578.0    0.316609    0.465556  0.0    0.000000    0.000000   \n",
       "DSS.time         578.0  841.141869  864.070960  0.0  304.000000  577.500000   \n",
       "DSS.time.months  578.0   27.653676   28.407501  0.0    9.994411   18.986093   \n",
       "\n",
       "                         75%          max  \n",
       "DSS                 1.000000     1.000000  \n",
       "DSS.time         1094.000000  5546.000000  \n",
       "DSS.time.months    35.966729   182.332248  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39009937-b0b2-44c2-8890-297f9f6a940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1, 3, 5 year targets\n",
    "\n",
    "y_timeframes = []\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths = create_target_year(fianl_clean_data, y, 1)\n",
    "y_timeframes += [['Year1', Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths]]\n",
    "# y_timeframes += [['Year1', y['DSSYear1'], y['DSSYear1.time.months'], y['DSSYear1Bool']]]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths = create_target_year(fianl_clean_data, y, 3)\n",
    "y_timeframes += [['Year3', Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths]]\n",
    "# y['DSSYear3'], y['DSSYear3Bool'], y['DSSYear3.time.months'] = create_target_year(y, 3)\n",
    "#y_timeframes += [['Year3', y['DSSYear3'], y['DSSYear3.time.months'], y['DSSYear3Bool']]]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths = create_target_year(fianl_clean_data, y, 5)\n",
    "y_timeframes += [['Year5', Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths]]\n",
    "# y['DSSYear5'], y['DSSYear5Bool'], y['DSSYear5.time.months'] = create_target_year(y, 5)\n",
    "# y_timeframes += [['Year5', y['DSSYear5'], y['DSSYear5.time.months'], y['DSSYear5Bool']]]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths = create_target_year(fianl_clean_data, y, 7)\n",
    "y_timeframes += [['Year7', Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths]]\n",
    "\n",
    "y_timeframes += [['End Of Study', X_train, X_test, y_train.DSS, y_test.DSS, y.DSS, y.DSSBool, y['DSS.time.months']]]\n",
    "# print('ytrain: ', np.bincount(y_train))\n",
    "# print('ytest: ', np.bincount(y_test))\n",
    "\n",
    "# y_timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94ef79f-2ec1-4cce-8200-7b86afcdfd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeframe: Year1\n",
      "DSS.time.months: count    578.000000\n",
      "mean      10.085170\n",
      "std        3.548388\n",
      "min        0.000000\n",
      "25%        9.994411\n",
      "50%       12.000000\n",
      "75%       12.000000\n",
      "max       12.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "Timeframe: Year3\n",
      "DSS.time.months: count    578.000000\n",
      "mean      20.359718\n",
      "std       12.195458\n",
      "min        0.000000\n",
      "25%        9.994411\n",
      "50%       18.986093\n",
      "75%       35.868396\n",
      "max       36.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "Timeframe: Year5\n",
      "DSS.time.months: count    578.000000\n",
      "mean      23.985639\n",
      "std       17.947579\n",
      "min        0.000000\n",
      "25%        9.994411\n",
      "50%       18.986093\n",
      "75%       35.966729\n",
      "max       60.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "Timeframe: Year7\n",
      "DSS.time.months: count    578.000000\n",
      "mean      25.802246\n",
      "std       22.131177\n",
      "min        0.000000\n",
      "25%        9.994411\n",
      "50%       18.986093\n",
      "75%       35.966729\n",
      "max       84.000000\n",
      "dtype: float64\n",
      "==================================================\n",
      "Timeframe: End Of Study\n",
      "DSS.time.months: count    578.000000\n",
      "mean      27.653676\n",
      "std       28.407501\n",
      "min        0.000000\n",
      "25%        9.994411\n",
      "50%       18.986093\n",
      "75%       35.966729\n",
      "max      182.332248\n",
      "Name: DSS.time.months, dtype: float64\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each time frame in y_timeframes\n",
    "for timeframe_name, Xtrain, Xtest, ytrain, ytest, yDSSBinary, yDSSBool, yDSSTimeMonths in y_timeframes:\n",
    "    print(f\"Timeframe: {timeframe_name}\")\n",
    "    print(f\"DSS.time.months: {yDSSTimeMonths.describe()}\")\n",
    "    print(\"=\" * 50)  # Just to separate each timeframe with a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4708643-cc90-4ca0-926c-d74416cf221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Year1:\n",
      "  Training data shape: (462, 403964)\n",
      "  Testing data shape: (116, 403964)\n",
      "  Training target distribution: [408  54]\n",
      "  Testing target distribution: [102  14]\n",
      "Data for Year3:\n",
      "  Training data shape: (462, 403964)\n",
      "  Testing data shape: (116, 403964)\n",
      "  Training target distribution: [350 112]\n",
      "  Testing target distribution: [88 28]\n",
      "Data for Year5:\n",
      "  Training data shape: (462, 403964)\n",
      "  Testing data shape: (116, 403964)\n",
      "  Training target distribution: [334 128]\n",
      "  Testing target distribution: [84 32]\n",
      "Data for Year7:\n",
      "  Training data shape: (462, 403964)\n",
      "  Testing data shape: (116, 403964)\n",
      "  Training target distribution: [326 136]\n",
      "  Testing target distribution: [82 34]\n",
      "Data for End of Study:\n",
      "  Training data shape: (462, 403964)\n",
      "  Testing data shape: (116, 403964)\n",
      "  Training target distribution: [316 146]\n",
      "  Testing target distribution: [79 37]\n"
     ]
    }
   ],
   "source": [
    "for name, frame in zip([\"Year1\", \"Year3\", \"Year5\", \"Year7\", \"End of Study\"], y_timeframes):\n",
    "    print(f\"Data for {name}:\")\n",
    "    _, Xtrain, Xtest, ytrain, ytest, _, _, _ = frame\n",
    "    print(\"  Training data shape:\", Xtrain.shape)\n",
    "    print(\"  Testing data shape:\", Xtest.shape)\n",
    "    print(\"  Training target distribution:\", np.bincount(ytrain))\n",
    "    print(\"  Testing target distribution:\", np.bincount(ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbac14b7-ab87-413c-ba70-4aac38226a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility pipeline debugging class\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        if Verbosity > 0:\n",
    "            print('--- Debug transform -------------------------------------------------------------\\n')\n",
    "            print('X: ', X.shape)\n",
    "            print('X: \\n', pd.DataFrame(X).head())\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if Verbosity > 0:\n",
    "            print('--- Debug fit -------------------------------------------------------------\\n')\n",
    "            print('X: ', X.shape)\n",
    "            print('X: \\n', pd.DataFrame(X).head())\n",
    "            with open('X.pkl', 'wb') as f:\n",
    "                pickle.dump(X, f)\n",
    "            print('y: ', y.shape)\n",
    "            print('y: \\n', pd.DataFrame(y).head())\n",
    "            with open('y.pkl', 'wb') as f:\n",
    "                pickle.dump(y, f)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b93a8a1d-2a0f-4926-821a-e8b05342fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with dtype 'object': []\n"
     ]
    }
   ],
   "source": [
    "# Assuming clinical_info is a pandas DataFrame already loaded\n",
    "\n",
    "# Select columns where dtype is 'object'\n",
    "object_columns = fianl_clean_data.select_dtypes(include=['object']).columns\n",
    "nomFeatureColNames=[]\n",
    "# Convert the Index object to a list\n",
    "nomFeatureColNames = object_columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "# nomFeatureColNames.remove('Unnamed: 0')\n",
    "# nomFeatureColNames.remove('ID')\n",
    "# nomFeatureColNames.remove('rec_ID')\n",
    "\n",
    "print(\"Columns with dtype 'object':\", nomFeatureColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b5aacd-433d-4d05-a096-ee05a1188e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding nominal features...,\n",
    "# nomFeatureColNames = ['Sex', 'Smoking_2groups','T','N','M','EGFR_mut','Co-mut','']\n",
    "# nomFeatureColNames += ['breast_carcinoma_surgical_procedure_name', 'PAM50Call_RNAseq', 'PAM50_mRNA_nature2012', '_PANCAN_CNA_PANCAN_K8', 'histological_type', 'new_neoplasm_event_type', 'tissue_source_site' ]\n",
    "# nomFeatureColNames += ['PAM50_mRNA_nature2012', '_PANCAN_CNA_PANCAN_K8', 'histological_type', 'new_neoplasm_event_type', 'tissue_source_site']\n",
    "nominal_categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(sparse_output=False)),\n",
    "        # ('dbg', Debug()),\n",
    "        # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ],\n",
    "    verbose=Verbosity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce5cf946-5e00-41f9-8bca-142ac6fc3478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming clinical_info is a pandas DataFrame already loaded\n",
    "\n",
    "# Select columns where dtype is 'object'\n",
    "numeric_columns = fianl_clean_data.select_dtypes(exclude=['object']).columns\n",
    "listOfNumericalColNames=[]\n",
    "# Convert the Index object to a list\n",
    "listOfNumericalColNames = numeric_columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "\n",
    "# listOfNumericalColNames.remove('OS.time')\n",
    "print(\"Columns with dtype 'object':\", listOfNumericalColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c5648e0-4759-43b4-9371-d91116ad0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verbosity =False\n",
    "# print(listOfNumericalColNames.count('T'))\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()),\n",
    "    # ('dbg', Debug())\n",
    "    ],\n",
    "    verbose=Verbosity\n",
    ")\n",
    "# mergeSurvivalClinicalGene.count('T')\n",
    "# listOfNumericalColNames.remove('OS')\n",
    "numericColsWithNans = pd.DataFrame(fianl_clean_data[listOfNumericalColNames].isna().sum()[lambda x : x > 0])\n",
    "\n",
    "numericColsWithNans.set_index(numericColsWithNans.index.astype(str), inplace=True)\n",
    "# numericColsWithNans.set_index('num__' + numericColsWithNans.index.astype(str), inplace=True)\n",
    "if Verbosity > 0:\n",
    "    print('\\nnumericColsWithNans: ', numericColsWithNans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70365ee0-4c18-4a4a-bedd-902ff12533be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility pipeline class for removing columns containing any NaN\n",
    "# to prepare data for models that cannot handle missing data\n",
    "class RemoveColsWithNan(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        if Verbosity > 0:\n",
    "            print('X.shape: ', X.shape)\n",
    "            # print('X type: ', type(X))\n",
    "        X.drop(columns=numericColsWithNans.index, inplace=True)\n",
    "        if Verbosity > 0:\n",
    "            print('\\nNaNCols\\n', numericColsWithNans.index)\n",
    "            print('\\nDropped ', numericColsWithNans.shape[0], ' columns\\n')\n",
    "            print('X.shape: ', X.shape)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c3e94cd-990b-47fa-ab59-745d3e3f04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"passthru\", 'passthrough', listOfNumericalColNames),\n",
    "        # (\"cat_ord\", ordinal_categorical_transformer, ordFeatureColNames),\n",
    "        # ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), [3]),\n",
    "        (\"cat_nom\", nominal_categorical_transformer, nomFeatureColNames)\n",
    "        # remainder='passthrough'\n",
    "        # (\"pass_through\", 'passthrough', listOfReadyColNames),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    verbose=Verbosity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bcd1709-beca-408a-9c06-54044c2a5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processor\n",
    "# def all_cols_selector(X):\n",
    "#     print(list(X.columns))\n",
    "#     return list(X.columns)\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scaler\", numeric_transformer, make_column_selector()),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    verbose=Verbosity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75a9305c-fe0e-44d0-b452-f6b5555d0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate feature importances for Cox PH algorithm\n",
    "def cox_fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    last_y = y\n",
    "    if Verbosity > 0:\n",
    "        print('n_features: ', n_features)\n",
    "    coxScores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis(alpha=0.1, verbose=0)\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j : j + 1]\n",
    "        m.fit(Xj, y)\n",
    "        if Verbosity > 0:\n",
    "            print(j, end=',')\n",
    "        coxScores[j] = m.score(Xj, y)\n",
    "\n",
    "    with open('coxScores.pkl', 'wb') as f:\n",
    "        pickle.dump(coxScores, f)\n",
    "\n",
    "    if Verbosity > 0:\n",
    "        print('\\nFinished fitting and scoring\\n')\n",
    "    return coxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "936e78a9-220c-40b2-a683-bc6b97894384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model evaluation results across target time horizons\n",
    "def plot_results(models_results, y_timeframes, verbosity):\n",
    "\n",
    "    x = np.arange(len(models_results['XGB']['timeframes'].keys()))  # the label locations\n",
    "\n",
    "    cIndex_vals = {}\n",
    "    for model in models_results.keys():\n",
    "        cIndex_vals[model] = []\n",
    "\n",
    "    for target in models_results['XGB']['timeframes'].keys():\n",
    "        if verbosity > 0:\n",
    "            print(target)\n",
    "            # print(models_results[model]['timeframes'].keys())\n",
    "\n",
    "        for model in models_results.keys():\n",
    "            if verbosity > 0:\n",
    "                print(model)\n",
    "                print(models_results[model]['timeframes'][target]['cIndex_test'])\n",
    "            cIndex_vals[model].append(models_results[model]['timeframes'][target]['cIndex_test'])\n",
    "\n",
    "    print(cIndex_vals)\n",
    "\n",
    "    for model, measurement in cIndex_vals.items():\n",
    "        plt.plot(x, measurement, label=model)\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    plt.ylabel(\"concordance index\")\n",
    "    plt.xlabel(\"analysis target timeframe\")\n",
    "    plt.xticks(x, models_results['XGB']['timeframes'].keys())\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title('Survival Prediction Accuracy by Time Horizon')\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac835d47-f076-4c68-974a-9493ddffb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53292c66-8dd7-4f62-879e-7552342db709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 462 entries, 731.0 to 237.0\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DSS       462 non-null    float64\n",
      " 1   DSS_time  462 non-null    float64\n",
      " 2   DSSBool   462 non-null    bool   \n",
      "dtypes: bool(1), float64(2)\n",
      "memory usage: 27.4 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 462 entries, 731.0 to 237.0\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DSS       462 non-null    float64\n",
      " 1   DSS_time  462 non-null    float64\n",
      " 2   DSSBool   462 non-null    bool   \n",
      "dtypes: bool(1), float64(2)\n",
      "memory usage: 27.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# yBool_length = len(y_train.DSSBool)\n",
    "# yODSSTime_length = len(X_train.DSS_Time_nature2012)\n",
    "y_train.info()\n",
    "# Assuming y_train is a pandas DataFrame already loaded\n",
    "\n",
    "# Rename the 'DSS.time' column to 'DSS_time'\n",
    "y_train = y_train.rename(columns={'DSS.time': 'DSS_time'})\n",
    "\n",
    "# Optionally, check the change by printing the DataFrame info to confirm the rename\n",
    "print(y_train.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ff32464-f872-4dda-9745-4840fb7d4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of yBool: 462\n",
      "Length of yDSSTime: 462\n"
     ]
    }
   ],
   "source": [
    "yBool_length = len(y_train.DSSBool)\n",
    "yDSSTime_length = len(y_train.DSS_time)\n",
    "\n",
    "print(f\"Length of yBool: {yBool_length}\")\n",
    "print(f\"Length of yDSSTime: {yDSSTime_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d70517bd-4cd9-46bb-9f69-034a83553432",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = [index for index in ytrain.index if index < yBool_length and index < yDSSTime_length]\n",
    "ytrain_filtered = ytrain[valid_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5738aead-25d8-48b9-9600-8d8f911c5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ytest.index: 116\n",
      "Length of yBool: 462\n",
      "Length of yDSSTime: 462\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of ytest.index:\", len(ytest.index))\n",
    "print(\"Length of yBool:\", yBool_length)\n",
    "print(\"Length of yDSSTime:\",yDSSTime_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc94c69d-0fd1-49ab-9bb2-58b15227f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\t00758722\\appdata\\roaming\\python\\python39\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\t00758722\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f11c434-a7b6-421d-8fbc-e762f6519074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"passthru\", 'passthrough', listOfNumericalColNames),\n",
    "        # (\"cat_ord\", ordinal_categorical_transformer, ordFeatureColNames),\n",
    "        # ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), [3]),\n",
    "        (\"cat_nom\", nominal_categorical_transformer, nomFeatureColNames)\n",
    "        # remainder='passthrough'\n",
    "        # (\"pass_through\", 'passthrough', listOfReadyColNames),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    "    verbose=Verbosity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4934c08-cd05-4143-82b6-e8d9e3ba79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93f4f9ee-1bcc-4a20-9757-a572498b8232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit Model:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "\n",
      "Target:  Year1 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score train: 0.950\n",
      "\n",
      "Score Model on Test Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score: 0.871\n",
      "cIndex_test:  0.8975265017667845\n",
      "\n",
      "Fit Model:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "\n",
      "Target:  Year3 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score train: 0.952\n",
      "\n",
      "Score Model on Test Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score: 0.922\n",
      "cIndex_test:  0.9037847697218422\n",
      "\n",
      "Fit Model:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "\n",
      "Target:  Year5 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score train: 0.972\n",
      "\n",
      "Score Model on Test Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score: 0.957\n",
      "cIndex_test:  0.9199438202247191\n",
      "\n",
      "Fit Model:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "\n",
      "Target:  Year7 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score train: 0.976\n",
      "\n",
      "Score Model on Test Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score: 0.974\n",
      "cIndex_test:  0.8511171910624715\n",
      "\n",
      "Fit Model:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "\n",
      "Target:  End Of Study ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score train: 0.998\n",
      "\n",
      "Score Model on Test Set:  LogisticRegression(random_state=42, verbose=False) ---------------------------------------------\n",
      "model score: 1.000\n",
      "cIndex_test:  0.8535620052770448\n",
      "116.58551216125488 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # start the timer\n",
    "classifiers = [\n",
    "    ['Log Reg', LogisticRegression(verbose=Verbosity,\n",
    "                                   random_state=randomState)],\n",
    "#     ['XGB', xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "#                               verbosity=Verbosity,\n",
    "#                               reg_lambda=5.0,\n",
    "#                               random_state=randomState,\n",
    "#                               max_depth=4,\n",
    "#                               min_child_weight=6,\n",
    "#                               subsample=0.8,\n",
    "#                               colsample_bytree=0.8,\n",
    "#                               n_estimators=1000,\n",
    "#                               learning_rate=0.01,\n",
    "#                               enable_categorical=True)],\n",
    "    # ['MLP', MLPClassifier(max_iter=300, verbose=Verbosity, random_state=randomState)],\n",
    "#    ['SVM', SVC(kernel='linear',probability=True, verbose=True, random_state=randomState)],\n",
    "#    ['HistGB', HistGradientBoostingClassifier(verbose=Verbosity)],\n",
    "    # ['SVM', LinearSVC(verbose=True, random_state=randomState)]\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "steps = [\n",
    "#         ('preprocess', preprocessor),\n",
    "        ('scaler', scaler),\n",
    "#         (\"stripNaNCols\", RemoveColsWithNan()),\n",
    "        (\"selectK\", SelectKBest(k=25)),\n",
    "        # (\"dump\", Dump()),\n",
    "        # ('select', fs),\n",
    "]\n",
    "pipeline = Pipeline(steps, memory='/kaggle/working/mInfoPipecache', verbose=Verbosity)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    pipeline.steps.append(['selectRFECV', RFECV(estimator=deepcopy(classifier), step=1, verbose=Verbosity)])\n",
    "    pipeline.steps.append(['clf', classifier])\n",
    "    models_results[name] = {'model': classifier}\n",
    "    models_results[name]['pipeline'] = deepcopy(pipeline)\n",
    "    models_results[name]['timeframes'] = {}\n",
    "\n",
    "    for timeframe_name, Xtrain, Xtest, ytrain, ytest, y, yBool, yDSSTime in y_timeframes:\n",
    "        models_results[name]['timeframes'][timeframe_name] = {}\n",
    "        tf = models_results[name]['timeframes'][timeframe_name]\n",
    "\n",
    "#         cv_refcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=randomState)\n",
    "#         n_scores = cross_val_score(pipeline, mergeSurvivalClinicalGene, y, scoring='accuracy', cv=cv_refcv, n_jobs=-1)\n",
    "#         print('Accuracy: %.2f (%.2f)'% (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "        print('\\nFit Model: ', classifier, '---------------------------------------------')\n",
    "        print('\\nTarget: ', timeframe_name, '---------------------------------------------')\n",
    "        pipeline.fit(Xtrain, ytrain)\n",
    "\n",
    "        # Score the model against train set\n",
    "        print('\\nScore Model on Training Set: ', classifier, '---------------------------------------------')\n",
    "        tf['train_score'] = pipeline.score(Xtrain, ytrain)\n",
    "        print(\"model score train: %.3f\" % tf['train_score'])\n",
    "\n",
    "        # predict against train set\n",
    "        yHat_train = pipeline.predict(Xtrain)\n",
    "        tf['yHat_train'] = yHat_train\n",
    "\n",
    "        # predict probabilities, not just binary\n",
    "        yHat_train_prob = pipeline.predict_proba(Xtrain)\n",
    "        tf['yHat_train_prob'] = yHat_train_prob\n",
    "\n",
    "        # Score the model against Test Set\n",
    "        print('\\nScore Model on Test Set: ', classifier, '---------------------------------------------')\n",
    "        tf['test_score'] = pipeline.score(Xtest, ytest)\n",
    "        print(\"model score: %.3f\" % tf['test_score'])\n",
    "\n",
    "        # predict against test set\n",
    "        yHat_test = pipeline.predict(Xtest)\n",
    "        tf['yHat_test'] = yHat_test\n",
    "        tf['test_f1_score'] = f1_score(ytest, yHat_test)\n",
    "\n",
    "        # predict probabilities, not just binary\n",
    "        yHat_test_prob = pipeline.predict_proba(Xtest)\n",
    "        tf['yHat_test_prob'] = yHat_test_prob\n",
    "\n",
    "        # Score model performance as Concordance Index against Test Set\n",
    "        # Safe handling of indices when accessing yBool and yOSTime\n",
    "        safe_yBool = yBool.loc[ytest.index.intersection(yBool.index)]\n",
    "        safe_yDSSTime = yDSSTime.loc[ytest.index.intersection(yDSSTime.index)]\n",
    "\n",
    "        try:\n",
    "            tf['cIndex_test'] = concordance_index_censored(\n",
    "                safe_yBool,\n",
    "                safe_yDSSTime,\n",
    "                yHat_test_prob[:, 1])[0]\n",
    "            print('cIndex_test: ', tf['cIndex_test'])\n",
    "        except Exception as e:\n",
    "            print(\"Error calculating cIndex_test:\", e)\n",
    "\n",
    "        tf['pipeline'] = deepcopy(pipeline)\n",
    "        tf['model'] = deepcopy(classifier)\n",
    "\n",
    "    pipeline.steps.pop(-1)\n",
    "    pipeline.steps.pop(-1)\n",
    "\n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ab19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "633d76db-bc80-4828-b83f-b54981c4ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "\n",
      "Target:  Year1 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score train: 0.968\n",
      "\n",
      "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score: 0.871\n",
      "cIndex_test:  0.8773851590106007\n",
      "\n",
      "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "\n",
      "Target:  Year3 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score train: 0.955\n",
      "\n",
      "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score: 0.914\n",
      "cIndex_test:  0.9058367533059736\n",
      "\n",
      "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "\n",
      "Target:  Year5 ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score train: 0.957\n",
      "\n",
      "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score: 0.966\n",
      "cIndex_test:  0.8539325842696629\n",
      "\n",
      "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "\n",
      "Target:  Year7 ---------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score train: 0.970\n",
      "\n",
      "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score: 0.957\n",
      "cIndex_test:  0.8385772913816689\n",
      "\n",
      "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "\n",
      "Target:  End Of Study ---------------------------------------------\n",
      "\n",
      "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score train: 0.987\n",
      "\n",
      "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
      "model score: 1.000\n",
      "cIndex_test:  0.8535620052770448\n",
      "276.88050055503845 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # start the timer\n",
    "classifiers = [\n",
    "#     ['Log Reg', LogisticRegression(verbose=Verbosity,\n",
    "#                                    random_state=randomState)],\n",
    "    ['XGB', xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                              verbosity=0,\n",
    "                              reg_lambda=5.0,\n",
    "                              random_state=randomState,\n",
    "                              max_depth=4,\n",
    "                              min_child_weight=6,\n",
    "                              subsample=0.8,\n",
    "                              colsample_bytree=0.8,\n",
    "                              n_estimators=1000,\n",
    "                              learning_rate=0.01,\n",
    "                              enable_categorical=True)],\n",
    "    # ['MLP', MLPClassifier(max_iter=300, verbose=Verbosity, random_state=randomState)],\n",
    "#    ['SVM', SVC(kernel='linear',probability=True, verbose=True, random_state=randomState)],\n",
    "#    ['HistGB', HistGradientBoostingClassifier(verbose=Verbosity)],\n",
    "    # ['SVM', LinearSVC(verbose=True, random_state=randomState)]\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "steps = [\n",
    "#         ('preprocess', preprocessor),\n",
    "        ('scaler', scaler),\n",
    "#         (\"stripNaNCols\", RemoveColsWithNan()),\n",
    "        (\"selectK\", SelectKBest(k=25)),\n",
    "        # (\"dump\", Dump()),\n",
    "        # ('select', fs),\n",
    "]\n",
    "pipeline = Pipeline(steps, memory='/kaggle/working/mInfoPipecache', verbose=Verbosity)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    pipeline.steps.append(['selectRFECV', RFECV(estimator=deepcopy(classifier), step=1, verbose=Verbosity)])\n",
    "    pipeline.steps.append(['clf', classifier])\n",
    "    models_results[name] = {'model': classifier}\n",
    "    models_results[name]['pipeline'] = deepcopy(pipeline)\n",
    "    models_results[name]['timeframes'] = {}\n",
    "\n",
    "    for timeframe_name, Xtrain, Xtest, ytrain, ytest, y, yBool, yDSSTime in y_timeframes:\n",
    "        models_results[name]['timeframes'][timeframe_name] = {}\n",
    "        tf = models_results[name]['timeframes'][timeframe_name]\n",
    "\n",
    "#         cv_refcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=randomState)\n",
    "#         n_scores = cross_val_score(pipeline, mergeSurvivalClinicalGene, y, scoring='accuracy', cv=cv_refcv, n_jobs=-1)\n",
    "#         print('Accuracy: %.2f (%.2f)'% (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "        print('\\nFit Model: ', classifier, '---------------------------------------------')\n",
    "        print('\\nTarget: ', timeframe_name, '---------------------------------------------')\n",
    "        pipeline.fit(Xtrain, ytrain)\n",
    "\n",
    "        # Score the model against train set\n",
    "        print('\\nScore Model on Training Set: ', classifier, '---------------------------------------------')\n",
    "        tf['train_score'] = pipeline.score(Xtrain, ytrain)\n",
    "        print(\"model score train: %.3f\" % tf['train_score'])\n",
    "\n",
    "        # predict against train set\n",
    "        yHat_train = pipeline.predict(Xtrain)\n",
    "        tf['yHat_train'] = yHat_train\n",
    "\n",
    "        # predict probabilities, not just binary\n",
    "        yHat_train_prob = pipeline.predict_proba(Xtrain)\n",
    "        tf['yHat_train_prob'] = yHat_train_prob\n",
    "\n",
    "        # Score the model against Test Set\n",
    "        print('\\nScore Model on Test Set: ', classifier, '---------------------------------------------')\n",
    "        tf['test_score'] = pipeline.score(Xtest, ytest)\n",
    "        print(\"model score: %.3f\" % tf['test_score'])\n",
    "\n",
    "        # predict against test set\n",
    "        yHat_test = pipeline.predict(Xtest)\n",
    "        tf['yHat_test'] = yHat_test\n",
    "        tf['test_f1_score'] = f1_score(ytest, yHat_test)\n",
    "\n",
    "        # predict probabilities, not just binary\n",
    "        yHat_test_prob = pipeline.predict_proba(Xtest)\n",
    "        tf['yHat_test_prob'] = yHat_test_prob\n",
    "\n",
    "        # Score model performance as Concordance Index against Test Set\n",
    "        # Safe handling of indices when accessing yBool and yOSTime\n",
    "        safe_yBool = yBool.loc[ytest.index.intersection(yBool.index)]\n",
    "        safe_yDSSTime = yDSSTime.loc[ytest.index.intersection(yDSSTime.index)]\n",
    "\n",
    "        try:\n",
    "            tf['cIndex_test'] = concordance_index_censored(\n",
    "                safe_yBool,\n",
    "                safe_yDSSTime,\n",
    "                yHat_test_prob[:, 1])[0]\n",
    "            print('cIndex_test: ', tf['cIndex_test'])\n",
    "        except Exception as e:\n",
    "            print(\"Error calculating cIndex_test:\", e)\n",
    "\n",
    "        tf['pipeline'] = deepcopy(pipeline)\n",
    "        tf['model'] = deepcopy(classifier)\n",
    "\n",
    "    pipeline.steps.pop(-1)\n",
    "    pipeline.steps.pop(-1)\n",
    "\n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
