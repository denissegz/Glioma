{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#OS",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sksurv.meta import EnsembleSelection\nfrom sksurv.svm import FastSurvivalSVM, FastKernelSurvivalSVM\nfrom sksurv.tree import SurvivalTree\nfrom sksurv.ensemble import GradientBoostingSurvivalAnalysis\nfrom sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\nfrom sksurv.metrics import concordance_index_censored\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.compose import ColumnTransformer, make_column_selector\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\nfrom sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, VarianceThreshold, RFECV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\nfrom sklearn import set_config\nimport xgboost as xgb\nimport shap\nimport pickle\nimport time\nfrom copy import deepcopy\nfrom functools import cache\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrandomState = 42 # tip of the cap to Douglas Adams\nset_config(transform_output=\"pandas\")\nVerbosity = 0",
      "metadata": {},
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "fianl_clean_data = pd.read_pickle('fianl_clean_data.pkl')",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "fianl_clean_data.head",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         cg13869341  cg24669183  cg15560884  cg01014490  cg17505339  \\\n",
              "369.0     0.839668    0.622626    0.724557    0.013253    0.954777   \n",
              "96.0      0.887214    0.557666    0.709998    0.016885    0.909813   \n",
              "423.0     0.878038    0.821218    0.665864    0.017920    0.925042   \n",
              "370.0     0.857886    0.765783    0.677472    0.008228    0.952425   \n",
              "459.0     0.851489    0.727787    0.790580    0.011233    0.909230   \n",
              "...            ...         ...         ...         ...         ...   \n",
              "1097.0    0.916326    0.895041    0.689632    0.016836    0.931332   \n",
              "1101.0    0.888906    0.668552    0.649029    0.016283    0.924404   \n",
              "781.0     0.870023    0.920880    0.748541    0.017143    0.889875   \n",
              "782.0     0.842035    0.886402    0.708638    0.019360    0.936385   \n",
              "1089.0    0.837559    0.884514    0.680507    0.022893    0.913718   \n",
              "\n",
              "        cg11954957  cg16736630  cg05898754  cg03128332  cg16619049  ...  \\\n",
              "369.0     0.778680    0.937495    0.574408    0.256935    0.346032  ...   \n",
              "96.0      0.859712    0.885200    0.341588    0.088496    0.115528  ...   \n",
              "423.0     0.815867    0.818661    0.365594    0.115413    0.206443  ...   \n",
              "370.0     0.691414    0.915337    0.337019    0.258516    0.078493  ...   \n",
              "459.0     0.632709    0.839941    0.651802    0.071423    0.607906  ...   \n",
              "...            ...         ...         ...         ...         ...  ...   \n",
              "1097.0    0.839926    0.844833    0.409893    0.394330    0.745188  ...   \n",
              "1101.0    0.800694    0.893177    0.296759    0.086829    0.106427  ...   \n",
              "781.0     0.804467    0.861620    0.293793    0.111087    0.114814  ...   \n",
              "782.0     0.882608    0.903366    0.666527    0.125232    0.721306  ...   \n",
              "1089.0    0.818161    0.898309    0.419754    0.121404    0.850379  ...   \n",
              "\n",
              "        gender  initial_pathologic_dx_year  birth_days_to   OS  OS.time  DSS  \\\n",
              "369.0        1                      2004.0       -22392.0  1.0     24.0  1.0   \n",
              "96.0         0                      2001.0       -23343.0  1.0   1448.0  1.0   \n",
              "423.0        1                      2008.0       -18659.0  1.0    141.0  1.0   \n",
              "370.0        1                      2003.0       -19237.0  1.0     42.0  1.0   \n",
              "459.0        1                      2008.0       -15950.0  0.0    953.0  0.0   \n",
              "...        ...                         ...            ...  ...      ...  ...   \n",
              "1097.0       0                      2013.0        -9005.0  0.0    714.0  0.0   \n",
              "1101.0       1                      2013.0       -24411.0  1.0    245.0  1.0   \n",
              "781.0        1                      2013.0       -12578.0  0.0      7.0  0.0   \n",
              "782.0        1                      2013.0       -16202.0  0.0      6.0  0.0   \n",
              "1089.0       0                      2010.0       -15629.0  1.0    954.0  1.0   \n",
              "\n",
              "        DSS.time  PFI  PFI.time  classification.2021_simplified.labels  \n",
              "369.0       24.0  1.0      24.0                                      1  \n",
              "96.0      1448.0  1.0     797.0                                      1  \n",
              "423.0      141.0  1.0      81.0                                      1  \n",
              "370.0       42.0  1.0      42.0                                      1  \n",
              "459.0      953.0  0.0     953.0                                      0  \n",
              "...          ...  ...       ...                                    ...  \n",
              "1097.0     714.0  0.0     714.0                                      0  \n",
              "1101.0     245.0  1.0     245.0                                      1  \n",
              "781.0        7.0  0.0       7.0                                      2  \n",
              "782.0        6.0  0.0       6.0                                      0  \n",
              "1089.0     954.0  1.0     455.0                                      0  \n",
              "\n",
              "[578 rows x 403966 columns]>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# break out the target\n# print(mergeSurvivalClinicalGene.describe())\ny = fianl_clean_data[['OS']]\n# y['OSBool'] = y.OS.astype(bool) # this is the format scikit-survival needs\nfianl_clean_data.drop(columns=['OS'], inplace=True)\n# mergeSurvivalClinicalGene.describe().",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(fianl_clean_data, y, test_size=0.2, random_state=randomState, stratify=y)\n\nif Verbosity > 0:\n    print('X_train', X_train.shape), print('y_train', y_train.shape)\n    # print(np.bincount(y_train))\n    print('X_test', X_test.shape), print('y_test', y_test.shape)\n    # print(np.bincount(y_test))",
      "metadata": {},
      "outputs": [],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "source": "# now that we've split and stratified, supplement y with other elements of target\ny['OS.time'] = fianl_clean_data['OS.time']\ny_train['OS.time'] = X_train['OS.time']\ny_test['OS.time'] = X_test['OS.time']\nfianl_clean_data.drop(columns='OS.time', inplace=True)\nX_train.drop(columns='OS.time', inplace=True)\nX_test.drop(columns='OS.time', inplace=True)\n# yOS_train = [[y_train, X_train['OS.time']]\n# yOS_train = [[y_test, X_test['OS.time']]",
      "metadata": {},
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": "# create boolean target that scikit-survival needs\ny['OSBool'] = y.OS.astype(bool)\ny_train['OSBool'] = y_train.OS.astype(bool)\ny_test['OSBool'] = y_test.OS.astype(bool)",
      "metadata": {},
      "outputs": [],
      "execution_count": 64
    },
    {
      "cell_type": "code",
      "source": "# convert OS.time from days to months\n# this makes charts easier to interpret\ny['OS.time.months'] = y['OS.time'] / 30.417\n\nif Verbosity > 0:\n    y['OS.time.months']",
      "metadata": {},
      "outputs": [],
      "execution_count": 65
    },
    {
      "cell_type": "code",
      "source": "# Create Kaplan-Meier Survival Function for the entire dataset\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sksurv.nonparametric import kaplan_meier_estimator\n\nsurv_time, survival_prob, conf_int = kaplan_meier_estimator(\n    y.OSBool, y['OS.time.months'], conf_type=\"log-log\"\n    # data_y[\"Status\"], data_y[\"Survival_in_days\"], conf_type=\"log-log\"\n)\nplt.step(surv_time, survival_prob, where=\"post\")\nplt.fill_between(surv_time, conf_int[0], conf_int[1], alpha=0.25, step=\"post\")\nplt.ylim(0, 1)\nplt.title('Kaplan-Meier Survival Function')\nplt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\nplt.xlabel(\"time $t$ (months)\")\nplt.savefig(\"Kaplan-Meier Survival Function.png\")",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "source": "# function to format target for Scikit-Survival\n#\ndef format_target_for_Scikit_Survival(y):\n    # y: event boolean and event time, eg. y_train[['OSBool', 'OS.time']]\n    # List of tuples\n    aux = [(e1,e2) for e1,e2 in np.array(y)]\n    # aux = [(e1,e2) for e1,e2 in np.array(y[['OSBool', 'OS.time']])]\n\n    #Structured array\n    yOS = np.array(aux, dtype=[('Status', '?'), ('Survival_in_months', '<f8')])\n    # print(yOS)\n\n    return yOS",
      "metadata": {},
      "outputs": [],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "source": "# format target for Scikit-Survival\n\n#Structured array\nyOS = format_target_for_Scikit_Survival(y[['OSBool', 'OS.time']])\nif Verbosity > 0:\n    yOS",
      "metadata": {},
      "outputs": [],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "source": "# format target for Scikit-Survival\nyOS_train = format_target_for_Scikit_Survival(y_train[['OSBool', 'OS.time']])\nif Verbosity > 0:\n    yOS_train\n\nyOS_test = format_target_for_Scikit_Survival(y_test[['OSBool', 'OS.time']])\nif Verbosity > 0:\n    yOS_test",
      "metadata": {},
      "outputs": [],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": "# function to create additional target at 'years' years in to the study\ndef create_target_year(X, y, years):\n    OSBinary = []\n    OSTimeMonths = []\n\n    for sample_idx in range(len(y)):\n        # print(y.iloc[sample_idx])\n        if y.iloc[sample_idx]['OS.time.months'] <= (years * 12):\n            # print('In Cohort, OS= ', y.iloc[sample_idx].OS)\n            OSBinary.append(y.iloc[sample_idx].OS)\n            OSTimeMonths.append(y.iloc[sample_idx]['OS.time.months'])\n        else:\n            OSBinary.append(0) # censored\n            OSTimeMonths.append(years * 12)\n\n    OSBinary = pd.Series(OSBinary)\n    OSBool = OSBinary.astype(bool)\n    OSTimeMonths = pd.Series(OSTimeMonths)\n\n    # create balanced test and train sets\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, OSBinary, test_size=0.2, random_state=randomState, stratify=OSBinary)\n\n    if Verbosity > 0:\n        print('ytrain: ', np.bincount(ytrain))\n        print('ytrain: ', ytrain)\n        print('ytest: ', np.bincount(ytest))\n        print('ytrain: ', ytrain)\n\n    return Xtrain, Xtest, ytrain, ytest, OSBinary, OSBool, OSTimeMonths",
      "metadata": {},
      "outputs": [],
      "execution_count": 70
    },
    {
      "cell_type": "code",
      "source": "y.describe().transpose()",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>OS</th>\n",
              "      <td>578.0</td>\n",
              "      <td>0.326990</td>\n",
              "      <td>0.469520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OS.time</th>\n",
              "      <td>578.0</td>\n",
              "      <td>841.141869</td>\n",
              "      <td>864.070960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>577.500000</td>\n",
              "      <td>1094.000000</td>\n",
              "      <td>5546.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OS.time.months</th>\n",
              "      <td>578.0</td>\n",
              "      <td>27.653676</td>\n",
              "      <td>28.407501</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.994411</td>\n",
              "      <td>18.986093</td>\n",
              "      <td>35.966729</td>\n",
              "      <td>182.332248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                count        mean         std  min         25%         50%  \\\n",
              "OS              578.0    0.326990    0.469520  0.0    0.000000    0.000000   \n",
              "OS.time         578.0  841.141869  864.070960  0.0  304.000000  577.500000   \n",
              "OS.time.months  578.0   27.653676   28.407501  0.0    9.994411   18.986093   \n",
              "\n",
              "                        75%          max  \n",
              "OS                 1.000000     1.000000  \n",
              "OS.time         1094.000000  5546.000000  \n",
              "OS.time.months    35.966729   182.332248  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": "# create 1, 3, 5 year targets\n\ny_timeframes = []\n\nXtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths = create_target_year(fianl_clean_data, y, 1)\ny_timeframes += [['Year1', Xtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths]]\n# y_timeframes += [['Year1', y['OSYear1'], y['OSYear1.time.months'], y['OSYear1Bool']]]\n\nXtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths = create_target_year(fianl_clean_data, y, 3)\ny_timeframes += [['Year3', Xtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths]]\n# y['OSYear3'], y['OSYear3Bool'], y['OSYear3.time.months'] = create_target_year(y, 3)\n#y_timeframes += [['Year3', y['OSYear3'], y['OSYear3.time.months'], y['OSYear3Bool']]]\n\nXtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths = create_target_year(fianl_clean_data, y, 5)\ny_timeframes += [['Year5', Xtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths]]\n# y['OSYear5'], y['OSYear5Bool'], y['OSYear5.time.months'] = create_target_year(y, 5)\n# y_timeframes += [['Year5', y['OSYear5'], y['OSYear5.time.months'], y['OSYear5Bool']]]\n\nXtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths = create_target_year(fianl_clean_data, y, 7)\ny_timeframes += [['Year7', Xtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths]]\n\ny_timeframes += [['End Of Study', X_train, X_test, y_train.OS, y_test.OS, y.OS, y.OSBool, y['OS.time.months']]]\n# print('ytrain: ', np.bincount(y_train))\n# print('ytest: ', np.bincount(y_test))\n\n# y_timeframes",
      "metadata": {},
      "outputs": [],
      "execution_count": 72
    },
    {
      "cell_type": "code",
      "source": "# Iterate through each time frame in y_timeframes\nfor timeframe_name, Xtrain, Xtest, ytrain, ytest, yOSBinary, yOSBool, yOSTimeMonths in y_timeframes:\n    print(f\"Timeframe: {timeframe_name}\")\n    print(f\"OS.time.months: {yOSTimeMonths.describe()}\")\n    print(\"=\" * 50)  # Just to separate each timeframe with a line",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Timeframe: Year1\n",
            "OS.time.months: count    578.000000\n",
            "mean      10.085170\n",
            "std        3.548388\n",
            "min        0.000000\n",
            "25%        9.994411\n",
            "50%       12.000000\n",
            "75%       12.000000\n",
            "max       12.000000\n",
            "dtype: float64\n",
            "==================================================\n",
            "Timeframe: Year3\n",
            "OS.time.months: count    578.000000\n",
            "mean      20.359718\n",
            "std       12.195458\n",
            "min        0.000000\n",
            "25%        9.994411\n",
            "50%       18.986093\n",
            "75%       35.868396\n",
            "max       36.000000\n",
            "dtype: float64\n",
            "==================================================\n",
            "Timeframe: Year5\n",
            "OS.time.months: count    578.000000\n",
            "mean      23.985639\n",
            "std       17.947579\n",
            "min        0.000000\n",
            "25%        9.994411\n",
            "50%       18.986093\n",
            "75%       35.966729\n",
            "max       60.000000\n",
            "dtype: float64\n",
            "==================================================\n",
            "Timeframe: Year7\n",
            "OS.time.months: count    578.000000\n",
            "mean      25.802246\n",
            "std       22.131177\n",
            "min        0.000000\n",
            "25%        9.994411\n",
            "50%       18.986093\n",
            "75%       35.966729\n",
            "max       84.000000\n",
            "dtype: float64\n",
            "==================================================\n",
            "Timeframe: End Of Study\n",
            "OS.time.months: count    578.000000\n",
            "mean      27.653676\n",
            "std       28.407501\n",
            "min        0.000000\n",
            "25%        9.994411\n",
            "50%       18.986093\n",
            "75%       35.966729\n",
            "max      182.332248\n",
            "Name: OS.time.months, dtype: float64\n",
            "==================================================\n"
          ]
        }
      ],
      "execution_count": 73
    },
    {
      "cell_type": "code",
      "source": "for name, frame in zip([\"Year1\", \"Year3\", \"Year5\", \"Year7\", \"End of Study\"], y_timeframes):\n    print(f\"Data for {name}:\")\n    _, Xtrain, Xtest, ytrain, ytest, _, _, _ = frame\n    print(\"  Training data shape:\", Xtrain.shape)\n    print(\"  Testing data shape:\", Xtest.shape)\n    print(\"  Training target distribution:\", np.bincount(ytrain))\n    print(\"  Testing target distribution:\", np.bincount(ytest))\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data for Year1:\n",
            "  Training data shape: (462, 403965)\n",
            "  Testing data shape: (116, 403965)\n",
            "  Training target distribution: [407  55]\n",
            "  Testing target distribution: [102  14]\n",
            "Data for Year3:\n",
            "  Training data shape: (462, 403965)\n",
            "  Testing data shape: (116, 403965)\n",
            "  Training target distribution: [348 114]\n",
            "  Testing target distribution: [87 29]\n",
            "Data for Year5:\n",
            "  Training data shape: (462, 403965)\n",
            "  Testing data shape: (116, 403965)\n",
            "  Training target distribution: [329 133]\n",
            "  Testing target distribution: [83 33]\n",
            "Data for Year7:\n",
            "  Training data shape: (462, 403965)\n",
            "  Testing data shape: (116, 403965)\n",
            "  Training target distribution: [321 141]\n",
            "  Testing target distribution: [81 35]\n",
            "Data for End of Study:\n",
            "  Training data shape: (462, 403965)\n",
            "  Testing data shape: (116, 403965)\n",
            "  Training target distribution: [311 151]\n",
            "  Testing target distribution: [78 38]\n"
          ]
        }
      ],
      "execution_count": 74
    },
    {
      "cell_type": "code",
      "source": "# utility pipeline debugging class\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nclass Debug(BaseEstimator, TransformerMixin):\n\n    def transform(self, X):\n        if Verbosity > 0:\n            print('--- Debug transform -------------------------------------------------------------\\n')\n            print('X: ', X.shape)\n            print('X: \\n', pd.DataFrame(X).head())\n        return X\n\n    def fit(self, X, y=None, **fit_params):\n        if Verbosity > 0:\n            print('--- Debug fit -------------------------------------------------------------\\n')\n            print('X: ', X.shape)\n            print('X: \\n', pd.DataFrame(X).head())\n            with open('X.pkl', 'wb') as f:\n                pickle.dump(X, f)\n            print('y: ', y.shape)\n            print('y: \\n', pd.DataFrame(y).head())\n            with open('y.pkl', 'wb') as f:\n                pickle.dump(y, f)\n        return self",
      "metadata": {},
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "code",
      "source": "# Assuming clinical_info is a pandas DataFrame already loaded\n\n# Select columns where dtype is 'object'\nobject_columns = fianl_clean_data.select_dtypes(include=['object']).columns\nnomFeatureColNames=[]\n# Convert the Index object to a list\nnomFeatureColNames = object_columns.tolist()\n\n# Print the list of column names\n# nomFeatureColNames.remove('Unnamed: 0')\n# nomFeatureColNames.remove('ID')\n# nomFeatureColNames.remove('rec_ID')\n\nprint(\"Columns with dtype 'object':\", nomFeatureColNames)\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns with dtype 'object': []\n"
          ]
        }
      ],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": "# encoding nominal features...,\n# nomFeatureColNames = ['Sex', 'Smoking_2groups','T','N','M','EGFR_mut','Co-mut','']\n# nomFeatureColNames += ['breast_carcinoma_surgical_procedure_name', 'PAM50Call_RNAseq', 'PAM50_mRNA_nature2012', '_PANCAN_CNA_PANCAN_K8', 'histological_type', 'new_neoplasm_event_type', 'tissue_source_site' ]\n# nomFeatureColNames += ['PAM50_mRNA_nature2012', '_PANCAN_CNA_PANCAN_K8', 'histological_type', 'new_neoplasm_event_type', 'tissue_source_site']\nnominal_categorical_transformer = Pipeline(\n    steps=[\n        (\"encoder\", OneHotEncoder(sparse_output=False)),\n        # ('dbg', Debug()),\n        # (\"selector\", SelectPercentile(chi2, percentile=50)),\n    ],\n    verbose=Verbosity\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": 77
    },
    {
      "cell_type": "code",
      "source": "# Assuming clinical_info is a pandas DataFrame already loaded\n\n# Select columns where dtype is 'object'\nnumeric_columns = fianl_clean_data.select_dtypes(exclude=['object']).columns\nlistOfNumericalColNames=[]\n# Convert the Index object to a list\nlistOfNumericalColNames = numeric_columns.tolist()\n\n# Print the list of column names\n\n# listOfNumericalColNames.remove('OS.time')\nprint(\"Columns with dtype 'object':\", listOfNumericalColNames)",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": "\n# print(listOfNumericalColNames.count('T'))\nnumeric_transformer = Pipeline(\n    steps=[(\"scaler\", StandardScaler()),\n    # ('dbg', Debug())\n    ],\n    verbose=Verbosity\n)\n# mergeSurvivalClinicalGene.count('T')\n# listOfNumericalColNames.remove('OS')\nnumericColsWithNans = pd.DataFrame(fianl_clean_data[listOfNumericalColNames].isna().sum()[lambda x : x > 0])\n\nnumericColsWithNans.set_index(numericColsWithNans.index.astype(str), inplace=True)\n# numericColsWithNans.set_index('num__' + numericColsWithNans.index.astype(str), inplace=True)\nif Verbosity > 0:\n    print('\\nnumericColsWithNans: ', numericColsWithNans)",
      "metadata": {},
      "outputs": [],
      "execution_count": 79
    },
    {
      "cell_type": "code",
      "source": "# utility pipeline class for removing columns containing any NaN\n# to prepare data for models that cannot handle missing data\nclass RemoveColsWithNan(BaseEstimator, TransformerMixin):\n\n    def transform(self, X):\n        if Verbosity > 0:\n            print('X.shape: ', X.shape)\n            # print('X type: ', type(X))\n        X.drop(columns=numericColsWithNans.index, inplace=True)\n        if Verbosity > 0:\n            print('\\nNaNCols\\n', numericColsWithNans.index)\n            print('\\nDropped ', numericColsWithNans.shape[0], ' columns\\n')\n            print('X.shape: ', X.shape)\n        return X\n\n    def fit(self, X, y=None, **fit_params):\n        return self",
      "metadata": {},
      "outputs": [],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": "# data pre-processor\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"passthru\", 'passthrough', listOfNumericalColNames),\n        # (\"cat_ord\", ordinal_categorical_transformer, ordFeatureColNames),\n        # ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), [3]),\n        (\"cat_nom\", nominal_categorical_transformer, nomFeatureColNames)\n        # remainder='passthrough'\n        # (\"pass_through\", 'passthrough', listOfReadyColNames),\n    ],\n    verbose_feature_names_out=False,\n    verbose=Verbosity,\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": 81
    },
    {
      "cell_type": "code",
      "source": "# data pre-processor\n# def all_cols_selector(X):\n#     print(list(X.columns))\n#     return list(X.columns)\n\nscaler = ColumnTransformer(\n    transformers=[\n        (\"scaler\", numeric_transformer, make_column_selector()),\n    ],\n    verbose_feature_names_out=False,\n    verbose=Verbosity,\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": "# function to calculate feature importances for Cox PH algorithm\ndef cox_fit_and_score_features(X, y):\n    n_features = X.shape[1]\n    last_y = y\n    if Verbosity > 0:\n        print('n_features: ', n_features)\n    coxScores = np.empty(n_features)\n    m = CoxPHSurvivalAnalysis(alpha=0.1, verbose=0)\n    for j in range(n_features):\n        Xj = X[:, j : j + 1]\n        m.fit(Xj, y)\n        if Verbosity > 0:\n            print(j, end=',')\n        coxScores[j] = m.score(Xj, y)\n\n    with open('coxScores.pkl', 'wb') as f:\n        pickle.dump(coxScores, f)\n\n    if Verbosity > 0:\n        print('\\nFinished fitting and scoring\\n')\n    return coxScores",
      "metadata": {},
      "outputs": [],
      "execution_count": 84
    },
    {
      "cell_type": "code",
      "source": "# plot model evaluation results across target time horizons\ndef plot_results(models_results, y_timeframes, verbosity):\n\n    x = np.arange(len(models_results['XGB']['timeframes'].keys()))  # the label locations\n\n    cIndex_vals = {}\n    for model in models_results.keys():\n        cIndex_vals[model] = []\n\n    for target in models_results['XGB']['timeframes'].keys():\n        if verbosity > 0:\n            print(target)\n            # print(models_results[model]['timeframes'].keys())\n\n        for model in models_results.keys():\n            if verbosity > 0:\n                print(model)\n                print(models_results[model]['timeframes'][target]['cIndex_test'])\n            cIndex_vals[model].append(models_results[model]['timeframes'][target]['cIndex_test'])\n\n    print(cIndex_vals)\n\n    for model, measurement in cIndex_vals.items():\n        plt.plot(x, measurement, label=model)\n\n\n    # Add some text for labels, title and custom x-axis tick labels, etc.\n    plt.ylabel(\"concordance index\")\n    plt.xlabel(\"analysis target timeframe\")\n    plt.xticks(x, models_results['XGB']['timeframes'].keys())\n    plt.legend(loc=\"best\")\n    plt.title('Survival Prediction Accuracy by Time Horizon')\n    plt.show()\n\n    return",
      "metadata": {},
      "outputs": [],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": "models_results = {}",
      "metadata": {},
      "outputs": [],
      "execution_count": 86
    },
    {
      "cell_type": "code",
      "source": "# yBool_length = len(y_train.OSBool)\n# yOSTime_length = len(X_train.OS_Time_nature2012)\ny_train.info()\n# Assuming y_train is a pandas DataFrame already loaded\n\n# Rename the 'OS.time' column to 'OS_time'\ny_train = y_train.rename(columns={'OS.time': 'OS_time'})\n\n# Optionally, check the change by printing the DataFrame info to confirm the rename\nprint(y_train.info())\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 462 entries, 449.0 to 352.0\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   OS       462 non-null    float64\n",
            " 1   OS.time  462 non-null    float64\n",
            " 2   OSBool   462 non-null    bool   \n",
            "dtypes: bool(1), float64(2)\n",
            "memory usage: 11.3 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 462 entries, 449.0 to 352.0\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   OS       462 non-null    float64\n",
            " 1   OS_time  462 non-null    float64\n",
            " 2   OSBool   462 non-null    bool   \n",
            "dtypes: bool(1), float64(2)\n",
            "memory usage: 11.3 KB\n",
            "None\n"
          ]
        }
      ],
      "execution_count": 87
    },
    {
      "cell_type": "code",
      "source": "yBool_length = len(y_train.OSBool)\nyOSTime_length = len(y_train.OS_time)\n\nprint(f\"Length of yBool: {yBool_length}\")\nprint(f\"Length of yOSTime: {yOSTime_length}\")",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of yBool: 462\n",
            "Length of yOSTime: 462\n"
          ]
        }
      ],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": "valid_indices = [index for index in ytrain.index if index < yBool_length and index < yOSTime_length]\nytrain_filtered = ytrain[valid_indices]\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 90
    },
    {
      "cell_type": "code",
      "source": "print(\"Length of ytest.index:\", len(ytest.index))\nprint(\"Length of yBool:\", yBool_length)\nprint(\"Length of yOSTime:\",yOSTime_length)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of ytest.index: 116\n",
            "Length of yBool: 462\n",
            "Length of yOSTime: 462\n"
          ]
        }
      ],
      "execution_count": 91
    },
    {
      "cell_type": "code",
      "source": "!pip install xgboost",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: xgboost in c:\\users\\t00733937\\appdata\\roaming\\python\\python39\\site-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\t00733937\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n"
          ]
        }
      ],
      "execution_count": 92
    },
    {
      "cell_type": "code",
      "source": "# data pre-processor\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"passthru\", 'passthrough', listOfNumericalColNames),\n        # (\"cat_ord\", ordinal_categorical_transformer, ordFeatureColNames),\n        # ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), [3]),\n        (\"cat_nom\", nominal_categorical_transformer, nomFeatureColNames)\n        # remainder='passthrough'\n        # (\"pass_through\", 'passthrough', listOfReadyColNames),\n    ],\n    verbose_feature_names_out=False,\n    verbose=Verbosity,\n)",
      "metadata": {},
      "outputs": [],
      "execution_count": 93
    },
    {
      "cell_type": "code",
      "source": "import xgboost as xgb\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 96
    },
    {
      "cell_type": "code",
      "source": "# train and score \"vanilla\" algorithms against each each time horizon...1, 3, 5, end of study\n# takes ~? minutes\n# Verbosity = 1\nstart_time = time.time() # start the timer\nclassifiers = [\n    ['Log Reg', LogisticRegression(verbose=Verbosity,\n                                   random_state=randomState)],\n    ['XGB', xgb.XGBClassifier(objective=\"binary:logistic\",\n                              verbosity=Verbosity,\n                              reg_lambda=5.0,\n                              random_state=randomState,\n                              max_depth=4,\n                              min_child_weight=6,\n                              subsample=0.8,\n                              colsample_bytree=0.8,\n                              n_estimators=1000,\n                              learning_rate=0.01,\n                              enable_categorical=True)],\n    # ['MLP', MLPClassifier(max_iter=300, verbose=Verbosity, random_state=randomState)],\n#    ['SVM', SVC(kernel='linear',probability=True, verbose=True, random_state=randomState)],\n#    ['HistGB', HistGradientBoostingClassifier(verbose=Verbosity)],\n    # ['SVM', LinearSVC(verbose=True, random_state=randomState)]\n    ]\n\n\n\n\nsteps = [\n#         ('preprocess', preprocessor),\n        ('scaler', scaler),\n#         (\"stripNaNCols\", RemoveColsWithNan()),\n        (\"selectK\", SelectKBest(k=25)),\n        # (\"dump\", Dump()),\n        # ('select', fs),\n]\npipeline = Pipeline(steps, memory='/kaggle/working/mInfoPipecache', verbose=Verbosity)\n\nfor name, classifier in classifiers:\n    pipeline.steps.append(['selectRFECV', RFECV(estimator=deepcopy(classifier), step=1, verbose=Verbosity)])\n    pipeline.steps.append(['clf', classifier])\n    models_results[name] = {'model': classifier}\n    models_results[name]['pipeline'] = deepcopy(pipeline)\n    models_results[name]['timeframes'] = {}\n\n    for timeframe_name, Xtrain, Xtest, ytrain, ytest, y, yBool, yOSTime in y_timeframes:\n        models_results[name]['timeframes'][timeframe_name] = {}\n        tf = models_results[name]['timeframes'][timeframe_name]\n\n#         cv_refcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=randomState)\n#         n_scores = cross_val_score(pipeline, mergeSurvivalClinicalGene, y, scoring='accuracy', cv=cv_refcv, n_jobs=-1)\n#         print('Accuracy: %.2f (%.2f)'% (np.mean(n_scores), np.std(n_scores)))\n\n        print('\\nFit Model: ', classifier, '---------------------------------------------')\n        print('\\nTarget: ', timeframe_name, '---------------------------------------------')\n        pipeline.fit(Xtrain, ytrain)\n\n        # Score the model against train set\n        print('\\nScore Model on Training Set: ', classifier, '---------------------------------------------')\n        tf['train_score'] = pipeline.score(Xtrain, ytrain)\n        print(\"model score train: %.3f\" % tf['train_score'])\n\n        # predict against train set\n        yHat_train = pipeline.predict(Xtrain)\n        tf['yHat_train'] = yHat_train\n\n        # predict probabilities, not just binary\n        yHat_train_prob = pipeline.predict_proba(Xtrain)\n        tf['yHat_train_prob'] = yHat_train_prob\n\n        # Score the model against Test Set\n        print('\\nScore Model on Test Set: ', classifier, '---------------------------------------------')\n        tf['test_score'] = pipeline.score(Xtest, ytest)\n        print(\"model score: %.3f\" % tf['test_score'])\n\n        # predict against test set\n        yHat_test = pipeline.predict(Xtest)\n        tf['yHat_test'] = yHat_test\n        tf['test_f1_score'] = f1_score(ytest, yHat_test)\n\n        # predict probabilities, not just binary\n        yHat_test_prob = pipeline.predict_proba(Xtest)\n        tf['yHat_test_prob'] = yHat_test_prob\n\n        # Score model performance as Concordance Index against Test Set\n        # Safe handling of indices when accessing yBool and yOSTime\n        safe_yBool = yBool.loc[ytest.index.intersection(yBool.index)]\n        safe_yOSTime = yOSTime.loc[ytest.index.intersection(yOSTime.index)]\n\n        try:\n            tf['cIndex_test'] = concordance_index_censored(\n                safe_yBool,\n                safe_yOSTime,\n                yHat_test_prob[:, 1])[0]\n            print('cIndex_test: ', tf['cIndex_test'])\n        except Exception as e:\n            print(\"Error calculating cIndex_test:\", e)\n\n        tf['pipeline'] = deepcopy(pipeline)\n        tf['model'] = deepcopy(classifier)\n\n    pipeline.steps.pop(-1)\n    pipeline.steps.pop(-1)\n\nprint('%s seconds' % (time.time() - start_time))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fit Model:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "\n",
            "Target:  Year1 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score train: 0.944\n",
            "\n",
            "Score Model on Test Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score: 0.905\n",
            "cIndex_test:  0.8899213724088635\n",
            "\n",
            "Fit Model:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "\n",
            "Target:  Year3 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score train: 0.959\n",
            "\n",
            "Score Model on Test Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score: 0.940\n",
            "cIndex_test:  0.9014084507042254\n",
            "\n",
            "Fit Model:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "\n",
            "Target:  Year5 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score train: 0.961\n",
            "\n",
            "Score Model on Test Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score: 0.966\n",
            "cIndex_test:  0.8683853459972863\n",
            "\n",
            "Fit Model:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "\n",
            "Target:  Year7 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score train: 0.968\n",
            "\n",
            "Score Model on Test Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score: 0.966\n",
            "cIndex_test:  0.8484112974404237\n",
            "\n",
            "Fit Model:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "\n",
            "Target:  End Of Study ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score train: 0.989\n",
            "\n",
            "Score Model on Test Set:  LogisticRegression(random_state=42) ---------------------------------------------\n",
            "model score: 0.991\n",
            "cIndex_test:  0.8322475570032574\n",
            "\n",
            "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "\n",
            "Target:  Year1 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score train: 0.957\n",
            "\n",
            "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score: 0.905\n",
            "cIndex_test:  0.870264474624732\n",
            "\n",
            "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "\n",
            "Target:  Year3 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score train: 0.961\n",
            "\n",
            "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score: 0.931\n",
            "cIndex_test:  0.8934575193094049\n",
            "\n",
            "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "\n",
            "Target:  Year5 ---------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score train: 0.972\n",
            "\n",
            "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score: 0.948\n",
            "cIndex_test:  0.8726820443238353\n",
            "\n",
            "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "\n",
            "Target:  Year7 ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score train: 0.968\n",
            "\n",
            "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score: 0.966\n",
            "cIndex_test:  0.8484112974404237\n",
            "\n",
            "Fit Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "\n",
            "Target:  End Of Study ---------------------------------------------\n",
            "\n",
            "Score Model on Training Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score train: 0.989\n",
            "\n",
            "Score Model on Test Set:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
            "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
            "              gamma=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
            "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
            "              multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
            "              num_parallel_tree=None, random_state=42, ...) ---------------------------------------------\n",
            "model score: 0.991\n",
            "cIndex_test:  0.8322475570032574\n",
            "393.43179202079773 seconds\n"
          ]
        }
      ],
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}